# üîç REAVALIA√á√ÉO: I/O Wait Alto em CPX31 com NVMe

**Data:** 25/11/2025  
**Servidor:** `flyingdonkeys.com.br` (37.27.1.242)  
**Plano Atual:** **CPX31** (j√° tem NVMe)  
**Problema:** I/O Wait alto (9-18%) mesmo com NVMe

---

## ‚ö†Ô∏è DESCOBERTA IMPORTANTE

**Servidor j√° √© CPX31:**
- ‚úÖ **CPU:** 4 cores
- ‚úÖ **RAM:** 7.6 GB (deve ser 16 GB - verificar)
- ‚úÖ **Disco:** NVMe (j√° inclu√≠do no CPX31)
- ‚ö†Ô∏è **I/O Wait:** 9-18% (ALTO mesmo com NVMe)

**Conclus√£o:** O problema **N√ÉO √© disco lento**. NVMe j√° est√° presente.

---

## üîç NOVAS CAUSAS POSS√çVEIS

Se o servidor j√° tem NVMe e I/O wait est√° alto, as causas podem ser:

### **1. Queries Lentas do Banco de Dados**

**Sintomas:**
- Muitas queries simult√¢neas
- Queries sem √≠ndices adequados
- Queries fazendo full table scan
- Locks de tabela

**Como verificar:**
```bash
# Verificar queries lentas (requer acesso MySQL)
docker exec espocrm-db mysql -uroot -p -e "SHOW PROCESSLIST;"
docker exec espocrm-db mysql -uroot -p -e "SHOW ENGINE INNODB STATUS\G"
```

**Solu√ß√£o:**
- Otimizar queries
- Adicionar √≠ndices
- Verificar locks

---

### **2. Muitas Opera√ß√µes de I/O Simult√¢neas**

**Sintomas:**
- Muitos processos acessando disco ao mesmo tempo
- Logs sendo escritos constantemente
- Cache do sistema insuficiente

**Como verificar:**
```bash
# Verificar processos com maior I/O
iotop
# ou
iostat -x 1 5
```

**Solu√ß√£o:**
- Reduzir frequ√™ncia de logs
- Aumentar cache do sistema
- Otimizar opera√ß√µes de escrita

---

### **3. Configura√ß√£o Inadequada do MySQL/MariaDB**

**Sintomas:**
- Buffer pool muito pequeno
- Cache insuficiente
- Configura√ß√µes n√£o otimizadas para NVMe

**Como verificar:**
```bash
# Verificar configura√ß√£o do MySQL
docker exec espocrm-db mysql -uroot -p -e "SHOW VARIABLES LIKE 'innodb_buffer_pool_size';"
docker exec espocrm-db mysql -uroot -p -e "SHOW VARIABLES LIKE 'innodb_log_file_size';"
```

**Solu√ß√£o:**
- Aumentar buffer pool
- Otimizar configura√ß√µes para NVMe
- Ajustar cache

---

### **4. Logs Muito Grandes (140 MB/dia)**

**Sintomas:**
- Logs sendo escritos constantemente
- Muitas opera√ß√µes de escrita em disco
- I/O wait alto durante escrita de logs

**Solu√ß√£o:**
- Implementar rota√ß√£o de logs
- Reduzir n√≠vel de log (se aplic√°vel)
- Limpar logs antigos

---

### **5. Container Docker com I/O Alto**

**Sintomas:**
- Container espocrm-daemon com CPU alto (11.79%)
- Muitas opera√ß√µes de I/O do container

**Solu√ß√£o:**
- Verificar o que o daemon est√° fazendo
- Otimizar processos do container

---

## üìä AN√ÅLISE: Por que I/O Wait Alto com NVMe?

### **NVMe vs I/O Wait:**

**NVMe √© r√°pido, mas:**
- ‚ö†Ô∏è I/O wait alto pode ocorrer mesmo com NVMe se:
  - H√° muitas opera√ß√µes simult√¢neas
  - Queries do banco s√£o lentas
  - Cache √© insuficiente
  - Configura√ß√µes n√£o est√£o otimizadas

**I/O Wait n√£o √© apenas velocidade do disco:**
- √â tamb√©m sobre **quantidade** de opera√ß√µes
- √â sobre **efici√™ncia** das opera√ß√µes
- √â sobre **configura√ß√£o** do sistema

---

## üéØ PR√ìXIMOS PASSOS DE INVESTIGA√á√ÉO

### **1. Verificar Queries do Banco de Dados**

```bash
# Verificar queries ativas
docker exec espocrm-db mysql -uroot -p$(docker exec espocrm-db printenv MYSQL_ROOT_PASSWORD) -e "SHOW PROCESSLIST;" 2>/dev/null

# Verificar queries lentas (se log estiver habilitado)
docker exec espocrm-db cat /var/log/mysql/slow-query.log 2>/dev/null | tail -50
```

---

### **2. Verificar Configura√ß√£o do MySQL**

```bash
# Verificar buffer pool
docker exec espocrm-db mysql -uroot -p$(docker exec espocrm-db printenv MYSQL_ROOT_PASSWORD) -e "SHOW VARIABLES LIKE 'innodb_buffer_pool_size';" 2>/dev/null

# Verificar outras configura√ß√µes importantes
docker exec espocrm-db mysql -uroot -p$(docker exec espocrm-db printenv MYSQL_ROOT_PASSWORD) -e "SHOW VARIABLES LIKE 'innodb%';" 2>/dev/null | head -20
```

---

### **3. Verificar Processos com Maior I/O**

```bash
# Verificar processos com I/O
ssh espo@37.27.1.242 "iotop -o -d 1 -n 5 2>/dev/null || echo 'iotop n√£o dispon√≠vel'"
```

---

### **4. Verificar Logs do EspoCRM**

```bash
# Verificar tamanho e frequ√™ncia de escrita
ssh espo@37.27.1.242 "ls -lh /var/www/espocrm/data/logs/ && echo '---' && tail -f /var/www/espocrm/data/logs/espo-$(date +%Y-%m-%d).log | head -20"
```

---

## üí° SOLU√á√ïES PROPOSTAS

### **Solu√ß√£o 1: Otimizar MySQL/MariaDB**

**A√ß√µes:**
1. Aumentar `innodb_buffer_pool_size` (se muito pequeno)
2. Otimizar configura√ß√µes para NVMe
3. Verificar e otimizar queries lentas
4. Adicionar √≠ndices onde necess√°rio

**Impacto esperado:** Redu√ß√£o de I/O wait para 5-10%

---

### **Solu√ß√£o 2: Implementar Rota√ß√£o de Logs**

**A√ß√µes:**
1. Configurar rota√ß√£o autom√°tica de logs
2. Limpar logs antigos
3. Reduzir frequ√™ncia de escrita

**Impacto esperado:** Redu√ß√£o parcial de I/O wait

---

### **Solu√ß√£o 3: Otimizar Container espocrm-daemon**

**A√ß√µes:**
1. Verificar o que o daemon est√° processando
2. Otimizar processos em background
3. Reduzir carga do daemon

**Impacto esperado:** Redu√ß√£o de CPU e poss√≠vel I/O

---

## üìã CHECKLIST DE INVESTIGA√á√ÉO

- [ ] Verificar queries lentas do banco de dados
- [ ] Verificar configura√ß√£o do MySQL/MariaDB
- [ ] Verificar processos com maior I/O
- [ ] Verificar frequ√™ncia de escrita de logs
- [ ] Verificar o que o container espocrm-daemon est√° fazendo
- [ ] Identificar causa raiz do I/O wait alto

---

## ‚ö†Ô∏è CONCLUS√ÉO

**Servidor j√° tem NVMe (CPX31):**
- ‚úÖ Disco n√£o √© o problema
- ‚ö†Ô∏è I/O wait alto tem outra causa

**Causas mais prov√°veis:**
1. Queries lentas do banco de dados
2. Configura√ß√£o inadequada do MySQL
3. Muitas opera√ß√µes de I/O simult√¢neas
4. Logs sendo escritos constantemente

**Pr√≥ximo passo:** Investigar queries do banco de dados e configura√ß√£o do MySQL.

---

**Documento criado em:** 25/11/2025  
**Status:** üîç **REAVALIA√á√ÉO CONCLU√çDA - NOVAS CAUSAS IDENTIFICADAS**

